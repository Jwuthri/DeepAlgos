{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "classes = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    "height, width = 128, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n",
      "instance length:  2304\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/raw/facial_expression/data.csv\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "lines = np.array(content)\n",
    "\n",
    "num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)\n",
    "print(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_emotions_count = dict()\n",
    "for i in range(1, len(lines)):\n",
    "    if classes[int(lines[i].split(\",\")[0])] in d_emotions_count.keys():\n",
    "        d_emotions_count[classes[int(lines[i].split(\",\")[0])]] += 1\n",
    "    else:\n",
    "        d_emotions_count[classes[int(lines[i].split(\",\")[0])]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a971438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = list(d_emotions_count.keys())\n",
    "b = list(d_emotions_count.values())\n",
    "y_pos = np.arange(len(a))\n",
    "plt.bar(y_pos, b, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, a)\n",
    "plt.ylabel('number')\n",
    "plt.title('emotion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'name_or_scope'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-80a01989ccef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"VALID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrelu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"VALID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'name_or_scope'"
     ]
    }
   ],
   "source": [
    "    init = tf.contrib.layers.xavier_initializer()\n",
    "    with tf.variable_scope():\n",
    "        conv1 = tf.layers.conv2d(inputs=images, filters=64, kernel_size=5, strides=1, padding=\"VALID\", kernel_initializer=init)\n",
    "        relu1 = tf.nn.relu(conv1)\n",
    "        conv2 = tf.layers.conv2d(inputs=relu1, filters=64, kernel_size=5, strides=1, padding=\"VALID\", kernel_initializer=init)\n",
    "        bn2 = tf.layers.batch_normalization(inputs=conv2, training=True)\n",
    "        relu2 = tf.nn.relu(bn2)\n",
    "        pool2 = tf.nn.max_pool(relu2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(inputs=pool2, filters=128, kernel_size=3, strides=2, padding=\"VALID\", kernel_initializer=init)\n",
    "        relu3 = tf.nn.relu(conv3)\n",
    "        conv4 = tf.layers.conv2d(inputs=relu3, filters=128, kernel_size=3, strides=2, padding=\"VALID\", kernel_initializer=init)\n",
    "        bn4 = tf.layers.batch_normalization(inputs=conv4, training=True)\n",
    "        relu4 = tf.nn.relu(bn4)\n",
    "        pool4 = tf.nn.avg_pool(relu4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "        conv5 = tf.layers.conv2d(inputs=pool4, filters=128, kernel_size=3, strides=2, padding=\"VALID\", kernel_initializer=init)\n",
    "        relu5 = tf.nn.relu(conv5)\n",
    "        conv6 = tf.layers.conv2d(inputs=relu5, filters=128, kernel_size=3, strides=2, padding=\"VALID\", kernel_initializer=init)\n",
    "        bn6 = tf.layers.batch_normalization(inputs=conv6, training=True)\n",
    "        relu6 = tf.nn.relu(bn6)\n",
    "        pool6 = tf.nn.avg_pool(relu6, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        shape = (-1, len(clases))\n",
    "        flat = tf.reshape(tensor=pool6, shape=shape)\n",
    "        logits = tf.layers.dense(inputs=flat, units=1024)\n",
    "        out = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        with tf.variable_scope(name_or_scope=\"discriminator\", reuse=reuse):\n",
    "            # Block 1 featuring\n",
    "            conv1 = tf.layers.conv2d(inputs=images, filters=64, kernel_size=5, strides=2, padding=\"same\", kernel_initializer=init)\n",
    "            relu1 = tf.maximum(conv1 * self.alpha, conv1)\n",
    "\n",
    "            # Block 2 featuring\n",
    "            conv2 = tf.layers.conv2d(inputs=relu1, filters=128, kernel_size=5, strides=2, padding=\"same\", kernel_initializer=init)\n",
    "            # Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n",
    "            bn2 = tf.layers.batch_normalization(inputs=conv2, training=True)\n",
    "            relu2 = tf.maximum(bn2 * self.alpha, bn2)\n",
    "            drop2 = tf.nn.dropout(x=relu2, keep_prob=.8)\n",
    "\n",
    "            # Block 3 featuring\n",
    "            conv3 = tf.layers.conv2d(inputs=drop2, filters=256, kernel_size=5, strides=2, padding=\"same\", kernel_initializer=init)\n",
    "            bn3 = tf.layers.batch_normalization(inputs=conv3, training=True)\n",
    "            relu3 = tf.maximum(bn3 * self.alpha, bn3)\n",
    "            drop3 = tf.nn.dropout(x=relu3, keep_prob=.8)\n",
    "\n",
    "            # Last Block prediction\n",
    "            shape = (-1, self.out_shape)\n",
    "            flat = tf.reshape(tensor=drop3, shape=shape)\n",
    "            logits = tf.layers.dense(inputs=flat, units=1)  # units: dimensionality of the output space.\n",
    "            out = tf.sigmoid(logits)\n",
    "\n",
    "            return logits, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
